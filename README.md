# Towards Semantic Versioning of Open Pre-trained Language Model Releases on Hugging Face
Recently, WhatsApp and Facebook have integrated Meta AI, built upon their latest and most advanced technology, Llama-3, into their applications. This allows users to leverage Meta AI for various tasks.
These advanced technologies are called pre-trained models. Many pre-trained models exist for different tasks, including Natural Language Processing (NLP), computer vision, and audio processing. The most common application of these technologies is large language processing (LLP), a subfield of NLP that focuses on enabling machines to understand,interpret, and generate human language. Pre-trained language models (PTLMs) are specifically designed for comprehending human language.
PTLMs vary in size, with parameter counts ranging from thousands to billions. Models with over 1 million parameters are sometimes called large language models, and are otherwise called PTLMs in our study, such as Llama, GPT, BERT, T5, and RoBERTa.
The good news is that many of these models are accessible through downstream model registries, allowing developers and users to leverage PTLMs in their applications. Several registries offer free access to pre-trained models for various downstream tasks, including Hugging Face (HF), ONNX, PyTorch, and Modelhub. Hugging Face is the largest of these,boasting over 800,000 pre-trained models. Exploring practices on this registry is valuable.
However, selecting the appropriate PTLM for specific applications can be challenging. Users face various hurdles, such as:
- Search terms: How to find the most suitable model?
- Variants: Which variant of PTLLM is available and recommended?
- Versions: What versions are available?

Unfortunately, no current documentation informs users about how these models are versioned on the model registries, the types of variants model developers push to model registry, and the naming convention. The AI community has yet to address these issues.
Therefore, it's crucial to explore the current naming conventions, versioning practices, and available variants of PTLMs and their characteristics. Similarly, it's important to understand if the versioning conventions, especially on Hugging Face align with those used in software development.

In this case, we employed a mixed-methods approach (quantitative and qualitative analysis) to make observations, which are discussed below.

## Naming and Versioning practices of PTLMs on HuggingFace
On HuggingFace, approximately 148 different naming practices are observed, indicating a significant level of inconsistency across repositories. This discrepancy may stem from a mismatch between user preferences and practical naming practices for PTLMs. Moreover, 13 key terms frequently appear in PTLLM names, including identifiers, base models, parameter sizes, training mechanisms, descriptions, variant types, versions, tasks, datasets, targeted languages, development dates, owning nationalities, and some ambiguous terms.

Regarding versioning, two main types of identifiers were observed: major (e.g., v1, v2) and minor (e.g., v1.x, v2.x), with major identifiers being more common. Additionally, files associated with PTLLM releases undergo frequent changes, with over 192 different file types identified across repositories. These files are categorized into five groups: Code files, Documentation files, Data and Configuration files, Model files, and Other files. The most frequently changed files are model binary files and data & configuration files.

Furthermore, there are 11 different file extensions used in storing model weights on Hugging Face, including .safetensor, .bin, .pt, .model, .onnx, .meta, .tflite, .mlmodel, .ckpt, .mdl, and .pb. Notably, .safetensor is the most prevalent extension, potentially indicating a community shift towards secure and efficient storage solutions.

## PTLMs provenance, variant types and their characteristics on Hugging Face
In evaluating PTLMs on Hugging Face, we've noted a focus on transparency and reproducibility. Many PTLMs are released with their configuration files, indicating an effort towards reproducible model training configurations. Since 2022, 299 unique base models have been released on Hugging Face, with Gemma, Mistral, Llama, Bert, and Mixtral being the most prevalent models. However, only 24% out of 52,227 of these PTLMs include information about their training datasets in their repositories.

Model developers on Hugging Face employ 15 different keywords, such as ft, deduped, and distilled, to denote variant types. These keywords are classified into four groups: Fine-tuning, Deduplication, Quantization, and Knowledge Distillation. Fine-tuned models emerge as the most prevalent, but a significant portion of released models do not specify their variant type.

Concerningly, only a small percentage of variant models include their training datasets in their repositories—22% for Fine-tuned models, 23% for Quantized models, 25% for Deduped models, and 36% for Distilled models. This transparency gap may impede user comprehension.

In terms of transparency, we found that 67% of released PTLMs on Hugging Face have model cards—a significant increase of 7% compared to previous literature findings, 60%. However, there is a notable disparity in model card release among variant types, with Deduped models exhibiting particularly low release rates at 31%. There are statistically significant differences between the release of model cards and the variant types of a model.

## Changes that lead to versioning of PTLLMs on Hugging Face.
We explored the versioning practices of PTLMs on Hugging Face to understand the changes leading to new versions. Developers use major and minor identifiers similar to those in software engineering. Our analysis revealed that only 43% of major versions and 35% of minor versions have their predecessors (for those with more than one version of a model) available, indicating poor versioning practices.
We found that changes to PTLMs for new versions include modifications to base models, binary files, binary file pointers, README documents, and model cards. Statistically significant changes were observed only in model binary files and base models, suggesting these are key differentiators for new versions.
Further examination of README and model cards for versions with changes in model weight files revealed 28 different changes between major versions and 8 between minor versions. Interestingly, all minor version changes also appeared in major versions. We categorized these changes into nine groups: configuration change, model architecture change, license change, performance change, dataset change, training library change, energy consumption change, evaluation metric change, and other changes. However, there was no statistical significance between changes in major and minor versions, suggesting arbitrary use of these identifiers by developers.
Lastly, we discovered that changes in configuration settings, training libraries, and evaluation metrics are associated with model performance improvements. This implies that altering these aspects can enhance the performance of new PTLLM versions.

## Towards Semantic Versioning of PTLMs 
### Versioning of PTLMs vs. traditional code 
The findings of this study highlight a fundamental difference between versioning for PTLMs and traditional code artifacts. In software, semantic versioning encodes backward compatibility and adherence to downstream client contracts into a concise, 1-dimensional numbering scheme (Preston-Werner, 2025). This approach relies on the clear definition of ’contracts’—the expectations and compatibility between artifacts and their clients—that allows semantic versioning to systematically indicate whether a version complies with or violates clients’ expectations (Lam et al., 2020). These contracts encapsulate essential details such as API specifications, backward compatibility, functionality additions or deprecations, and bug f ixes. However, PTLMs lack a direct counterpart to such contracts, i.e., there currently is no agreement on what compatibility means in the context of PTLMs. As our results demonstrate, PTLMs’ inherently multidimensional nature, encompassing characteristics such as architecture, size, training data, and domain specificity, complicates the application of semantic versioning principles and concepts. Furthermore, model owners currently try to project this multidimensionality onto a one-dimensional model name, but without an established naming convention, leading to ambiguities that challenge users in assessing compatibility and understanding the implications of changes (as we have pointed out in our findings). Unlike traditional software, PTLMs lack a standardized versioning framework due to their inherently multidimensional nature. This necessitates an approach that explicitly stores version metadata and enables automated compatibility assessments to streamline model adoption and evolution. In the following sections, we discuss (1) how to represent the ’version’ of a model, (2) how to determine the right ’version’ for a new model, and (3) how model version metadata can be accessed.
### How to Represent the “Version” of a Model 
Representing the version of deep learning models, particularly PTLMs, presents challenges that go beyond traditional software versioning. Semantic versioning (e.g., X.Y.Z) has been pivotal in software development, helping to prevent “dependency hell” by clearly signaling the nature of changes between versions (Lam et al., 2020, Preston-Werner, 2025). This one-dimensional structure of version numbering excels in signaling backward compatibility—where major version increments (X) indicate breaking changes, minor version increments (Y) represent new but compatible features, and patch version increments (Z) account for backward-compatible bug fixes. The one-dimensional approach of current semantic versioning assumes that changes can be captured in a linear, incremental fashion, but this simplicity cannot capture the complexity of PTLM evolution, due to the unique dynamics of model evolution. For instance, does changing the base model imply a major version update, or does it reflect a minor change? What about fine-tuning a model with an entirely new dataset—should this be classified as a major or minor change? Furthermore, configuration and license changes—often seen in model releases—may be viewed as relatively trivial, but should they constitute patch updates, or do they warrant a more significant version change? These uncertainties illustrate the difficulty of defining “backward compatibility” for PTLMs. While in traditional software, backward compatibility refers to a new version not breaking existing functionality, for PTLMs, model changes such as data shifts, architecture changes, or training adjustments may not fit into the established categories of software versioning. This makes it challenging to determine if a model is backward compatible in the same way as software, as modifications to models do not always directly correspond to “breaking” or “compatible” changes within the versioning system. Therefore, PTLM versioning requires a more effective approach, one that accounts for factors beyond functional compatibility, such as dataset shifts, model architecture, task specificity, reuse methods, and training dataset modifications. For instance, a minor adjustment in hyperparameters might not necessitate a major version update under traditional schemes, but it could have significant downstream impacts. Our study reveals that existing naming practices on Hugging Face often attempt to embed information about model changes, albeit inconsistently. Beyond compatibility, a critical aspect of semantic versioning should be the inclusion of provenance information—details about a model’s origin and the transformations it has undergone. In the context of versioning PTLMs, our paper identifies specific fields that may be important for a more accurate versioning system. These include: identifier, base model, model size, and training mechanisms. By incorporating these fields, versioning could better reflect the nuances of model evolution and provide users with more transparent, traceable information. Such an approach would not only improve compatibility assessments but also enhance reproducibility, enabling users to track and understand the evolution of models over time.
### How the Right “Version” Can Be Determined for a New Model 
Once a complete representation of semantic versioning for pre-trained language models is determined, determining the appropriate version “number” for a new model version requires evaluating how its changes impact backward compatibility and performance. Current practices, as observed in our study, lack systematic tools for this evaluation, resulting in inconsistent version tagging. For example, on Hugging Face, models fine-tuned on new datasets are often assigned major version identifiers, which contradicts the semantic versioning principle that major version increments (X) should be reserved for backward-incompatible changes. In contrast, fine-tuning a model with a new dataset typically results in a less significant change than altering the base model itself, which may not warrant a major version increment. Instead, a minor version update (Y) is more appropriate in these scenarios. This inconsistency highlights the need for a more structured and standardized approach to version generation. Building on the concept of semantic version calculators (Preston-Werner, 2025), (Lam et al., 2020) proposed using contracts as inputs for these tools. Extending this idea to PTLMs could involve incorporating model configuration changes, model architecture updates, performance variations, dataset modifications, and dependency changes into the contract. Such an adaptation would provide a framework more suited to the unique needs of PTLMs. Without dedicated tools, developers often rely on intuition or ad hoc practices, which may not fully capture the different changes. Model registries such as Hugging Face could benefit from integrating semantic version calculators to foster consistency, encourage the adoption of community-driven standards, and support users in making the final decision about the right version number. This would enhance transparency and build trust in the evolution of PTLMs.
### How Model Version Metadata can be accessed 
Currently, Hugging Face lacks dedicated fields to store versioning metadata, which forces developers to embed such details in model names. The absence of standardized naming conventions contributes to inconsistencies, making it challenging for users to interpret model changes systematically. While names often include attributes like model size, base model name, and training mechanism, the lack of uniformity results in overloading model names with information, compromising clarity and usability. Short-term efforts should prioritize establishing standard naming guidelines to mitigate these issues and promote consistency across repositories. In the long term, repositories must address this limitation by introducing structured metadata fields for versioning. These fields should explicitly capture version numbers (e.g., X.Y.Z or a future multi-dimensional representation), compatibility information, and key attributes such as model architecture or task alignment. Decoupling versioning information from model names would establish a more robust framework for tracking changes and ensuring reproducibility. Moreover, incorporating provenance information within model cards or as a separate metadata field would further enhance transparency and accountability in version management, aligning with best practices observed in other domains, such as software supply chain management (e.g., SBOMs). Therefore, based on our results, we believe the minimal set of essential segments to include in standardized naming or in multidimensional version representations should encompass identifiers, base model information, model size, and training mechanism. As a result, we emphasize the need to standardize naming practices in the short term, and advocate for long-term investments in accessible version metadata. In addition to the need for semantic versioning calculators, future research could explore integrating software bill of materials (SBOM)-inspired tools to decouple versioning and provenance information. SBOM is a formal machine-readable inventory of the components (and their dependency relationships) used for producing a software product (Xia et al., 2023). By redefining existing software compatibility notions for PTLMs and establishing robust standards, the ML community can enhance the usability, reproducibility, and transparency of its models. Addressing these challenges requires collaborative efforts between model developers, repository maintainers, and the broader research community, ensuring that PTLM versioning evolves alongside advancements in ML technology.

## The folders
- dataset_folder: This folder contain all the dataset used for the analysis in this study.
- RQ1_results: This folder contains the graphs and the randomly selected candidates for the manual analysis we condicted in this study for RQ1
- RQ2_result: This folder also contain the graphs and some other related information.
- RQ3_result: This folder also contain the figure and the randomly sampled candidate for the manual analysis we performed in this study.
- The .py and .ipynb files: These files contain the codes for the result analysis.

## Requirements
- Python programming language
- Python libraries:
  *  Beautifulsoup
  *  Requests
  *  Pandas
  *  Huggingface_hub
  *  Numpy
  *  Seaborn
  *  Matplotlib

## Authors
- Ajibode Adekunle
- Abdul Ali Bangash
- Filipe Roseiro Cogo
- Bram Adams
- Ahmed E. Hassan

## Citation
Ajibode, A., Bangash, A. A., Cogo, F. R., Adams, B., & Hassan, A. E. (2025). Towards semantic versioning of open pre-trained language model releases on hugging face. Empirical Software Engineering, 30(3), 1-63.
